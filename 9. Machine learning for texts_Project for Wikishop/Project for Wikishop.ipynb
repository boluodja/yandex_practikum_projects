{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ОПИСАНИЕ:__ Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. \n",
    "\n",
    "__ЦЕЛЬ:__\n",
    "Создать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "__ЗАДАЧИ:__ \n",
    "1. Обучить модель классифицировать комментарии на позитивные и негативные\n",
    "2. Достичь метрику качества *F1* не менее 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-фич\" data-toc-modified-id=\"Подготовка-фич-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подготовка фич</a></span></li><li><span><a href=\"#Логичтическая-регрессия\" data-toc-modified-id=\"Логичтическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Логичтическая регрессия</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Catboost</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-предобученной-модели-DistilBERT-и-токенизатора\" data-toc-modified-id=\"Загрузка-предобученной-модели-DistilBERT-и-токенизатора-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Загрузка предобученной модели DistilBERT и токенизатора</a></span></li><li><span><a href=\"#Padding\" data-toc-modified-id=\"Padding-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Padding</a></span></li><li><span><a href=\"#Masking\" data-toc-modified-id=\"Masking-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Masking</a></span></li><li><span><a href=\"#Обучение-модели\" data-toc-modified-id=\"Обучение-модели-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Обучение модели</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>CatBoost</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/vladimirgavrilev/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "from tqdm import notebook \n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_wiki.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Заметка__\n",
    "- всего порядка 160 тысяч объектов\n",
    "- десятая доля описания товаров промаркирована как токсичная\n",
    "- явных дубликатов нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем текст в нижний регистр\n",
    "df_wiki['text'] = df_wiki['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation\\nwhy the edits made under my usern...      0\n",
       "1  d'aww! he matches this background colour i'm s...      0\n",
       "2  hey man, i'm really not trying to edit war. it...      0\n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0\n",
       "4  you, sir, are my hero. any chance you remember...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Подготовка фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для отметки POS-тега\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\t\t\n",
    "        return None\n",
    "\n",
    "# функция вернет лемму каждого слова\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # токенизируем предложение и найдем тег POS для каждого токена\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), nltk.pos_tag(nltk.word_tokenize(text))))\n",
    "    \n",
    "    lemmatized_text = []\n",
    "    \n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # если нет доступного тега, оставим токен как есть\n",
    "            lemmatized_text.append(word)\n",
    "        else:\n",
    "            lemmatized_text.append(lemmatizer.lemmatize(word, tag))\n",
    "            \n",
    "    return (\" \".join(lemmatized_text))\n",
    "\n",
    "# функция оставит в тексте только латинские символы и пробелы\n",
    "def clear_text(text):\n",
    "    text_ = re.sub(r\"[^a-z]\", ' ', text) # находит в тексте все совпадения по шаблону и заменяет их заданной строкой.\n",
    "    return ' '.join(text_.split()) # пробелы устраняются комбинацией функций join() и split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "df_wiki['lemm_text'] = df_wiki['text'].apply(lambda x: lemmatize(clear_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation\\nwhy the edits made under my usern...      0   \n",
       "1  d'aww! he matches this background colour i'm s...      0   \n",
       "2  hey man, i'm really not trying to edit war. it...      0   \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
       "4  you, sir, are my hero. any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим фичи и таргеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_wiki['lemm_text']\n",
    "target = df_wiki['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = 0.2,random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим список стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vladimirgavrilev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "# создадим счётчик, указав в нём стоп-слова:\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет TF-IDF для корпуса текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(features_train) \n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логичтическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    114670\n",
       "1     12986\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим логистическую регрессию с применением кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 14s, sys: 1min 36s, total: 8min 51s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight={1: 9}, random_state=123,\n",
       "                                          solver='liblinear'),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "lr_model = LogisticRegression(random_state = 123, \n",
    "                              solver = 'liblinear', \n",
    "                              class_weight={1: 9})\n",
    "\n",
    "grid_search = GridSearchCV(lr_model, # задаем модель\n",
    "                           lr_parameters, # гиперпараметры\n",
    "                           cv = 5, # количество разбиений на кросс-валидацию ( < 3 делать не стоит)\n",
    "                           scoring = 'f1' # по какой метрике будем оценивать модель \n",
    "                           )  \n",
    "#обучение модели \n",
    "grid_search.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7536651510337359"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7546091181935115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_\n",
    "f1_score(target_test, grid_search.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5153424\ttotal: 5.14s\tremaining: 8m 28s\n",
      "1:\tlearn: 0.4695340\ttotal: 10.8s\tremaining: 8m 47s\n",
      "2:\tlearn: 0.4350017\ttotal: 16.3s\tremaining: 8m 47s\n",
      "3:\tlearn: 0.4075823\ttotal: 21.8s\tremaining: 8m 44s\n",
      "4:\tlearn: 0.3888728\ttotal: 27.5s\tremaining: 8m 42s\n",
      "5:\tlearn: 0.3748971\ttotal: 33s\tremaining: 8m 37s\n",
      "6:\tlearn: 0.3628253\ttotal: 38.6s\tremaining: 8m 32s\n",
      "7:\tlearn: 0.3530023\ttotal: 44.2s\tremaining: 8m 28s\n",
      "8:\tlearn: 0.3470480\ttotal: 49.7s\tremaining: 8m 22s\n",
      "9:\tlearn: 0.3407501\ttotal: 55.3s\tremaining: 8m 17s\n",
      "10:\tlearn: 0.3333196\ttotal: 1m\tremaining: 8m 12s\n",
      "11:\tlearn: 0.3245971\ttotal: 1m 6s\tremaining: 8m 7s\n",
      "12:\tlearn: 0.3174977\ttotal: 1m 12s\tremaining: 8m 2s\n",
      "13:\tlearn: 0.3085433\ttotal: 1m 17s\tremaining: 7m 57s\n",
      "14:\tlearn: 0.2998714\ttotal: 1m 23s\tremaining: 7m 51s\n",
      "15:\tlearn: 0.2945839\ttotal: 1m 28s\tremaining: 7m 46s\n",
      "16:\tlearn: 0.2886171\ttotal: 1m 34s\tremaining: 7m 41s\n",
      "17:\tlearn: 0.2833213\ttotal: 1m 40s\tremaining: 7m 35s\n",
      "18:\tlearn: 0.2782958\ttotal: 1m 45s\tremaining: 7m 30s\n",
      "19:\tlearn: 0.2747481\ttotal: 1m 51s\tremaining: 7m 25s\n",
      "20:\tlearn: 0.2703233\ttotal: 1m 56s\tremaining: 7m 19s\n",
      "21:\tlearn: 0.2667182\ttotal: 2m 2s\tremaining: 7m 14s\n",
      "22:\tlearn: 0.2630341\ttotal: 2m 8s\tremaining: 7m 9s\n",
      "23:\tlearn: 0.2594972\ttotal: 2m 13s\tremaining: 7m 3s\n",
      "24:\tlearn: 0.2558607\ttotal: 2m 19s\tremaining: 6m 58s\n",
      "25:\tlearn: 0.2528912\ttotal: 2m 25s\tremaining: 6m 52s\n",
      "26:\tlearn: 0.2508471\ttotal: 2m 30s\tremaining: 6m 47s\n",
      "27:\tlearn: 0.2477701\ttotal: 2m 36s\tremaining: 6m 41s\n",
      "28:\tlearn: 0.2448264\ttotal: 2m 41s\tremaining: 6m 36s\n",
      "29:\tlearn: 0.2430371\ttotal: 2m 47s\tremaining: 6m 30s\n",
      "30:\tlearn: 0.2409570\ttotal: 2m 53s\tremaining: 6m 25s\n",
      "0:\tlearn: 0.5201612\ttotal: 7.45s\tremaining: 12m 17s\n",
      "1:\tlearn: 0.4804178\ttotal: 14.7s\tremaining: 12m\n",
      "2:\tlearn: 0.4438012\ttotal: 22.3s\tremaining: 12m 1s\n",
      "3:\tlearn: 0.4169594\ttotal: 29.8s\tremaining: 11m 54s\n",
      "4:\tlearn: 0.4005298\ttotal: 37.4s\tremaining: 11m 50s\n",
      "5:\tlearn: 0.3844396\ttotal: 45.2s\tremaining: 11m 48s\n",
      "6:\tlearn: 0.3700731\ttotal: 52.9s\tremaining: 11m 42s\n",
      "7:\tlearn: 0.3629844\ttotal: 1m\tremaining: 11m 39s\n",
      "8:\tlearn: 0.3542224\ttotal: 1m 8s\tremaining: 11m 36s\n",
      "9:\tlearn: 0.3482970\ttotal: 1m 17s\tremaining: 11m 33s\n",
      "10:\tlearn: 0.3419381\ttotal: 1m 25s\tremaining: 11m 30s\n",
      "11:\tlearn: 0.3335026\ttotal: 1m 33s\tremaining: 11m 27s\n",
      "12:\tlearn: 0.3250590\ttotal: 1m 42s\tremaining: 11m 23s\n",
      "13:\tlearn: 0.3166078\ttotal: 1m 50s\tremaining: 11m 19s\n",
      "14:\tlearn: 0.3092232\ttotal: 1m 59s\tremaining: 11m 18s\n",
      "15:\tlearn: 0.3025002\ttotal: 2m 9s\tremaining: 11m 21s\n",
      "16:\tlearn: 0.2962488\ttotal: 2m 18s\tremaining: 11m 16s\n",
      "17:\tlearn: 0.2896532\ttotal: 2m 28s\tremaining: 11m 14s\n",
      "18:\tlearn: 0.2853526\ttotal: 2m 37s\tremaining: 11m 12s\n",
      "19:\tlearn: 0.2812558\ttotal: 2m 46s\tremaining: 11m 6s\n",
      "20:\tlearn: 0.2767823\ttotal: 2m 55s\tremaining: 10m 59s\n",
      "21:\tlearn: 0.2726567\ttotal: 3m 4s\tremaining: 10m 54s\n",
      "22:\tlearn: 0.2675436\ttotal: 3m 13s\tremaining: 10m 48s\n",
      "23:\tlearn: 0.2626987\ttotal: 3m 22s\tremaining: 10m 41s\n",
      "24:\tlearn: 0.2600119\ttotal: 3m 31s\tremaining: 10m 34s\n",
      "25:\tlearn: 0.2567596\ttotal: 3m 41s\tremaining: 10m 29s\n",
      "26:\tlearn: 0.2511652\ttotal: 3m 50s\tremaining: 10m 23s\n",
      "27:\tlearn: 0.2480050\ttotal: 4m\tremaining: 10m 18s\n",
      "28:\tlearn: 0.2457876\ttotal: 4m 10s\tremaining: 10m 12s\n",
      "29:\tlearn: 0.2435716\ttotal: 4m 20s\tremaining: 10m 7s\n",
      "30:\tlearn: 0.2404568\ttotal: 4m 30s\tremaining: 10m 2s\n",
      "31:\tlearn: 0.2384064\ttotal: 4m 41s\tremaining: 9m 57s\n",
      "32:\tlearn: 0.2359102\ttotal: 4m 51s\tremaining: 9m 52s\n",
      "33:\tlearn: 0.2335716\ttotal: 5m 2s\tremaining: 9m 47s\n",
      "34:\tlearn: 0.2317166\ttotal: 5m 13s\tremaining: 9m 42s\n",
      "35:\tlearn: 0.2299261\ttotal: 5m 24s\tremaining: 9m 36s\n",
      "36:\tlearn: 0.2263466\ttotal: 5m 35s\tremaining: 9m 31s\n",
      "37:\tlearn: 0.2235266\ttotal: 5m 46s\tremaining: 9m 25s\n",
      "38:\tlearn: 0.2208474\ttotal: 5m 57s\tremaining: 9m 19s\n",
      "39:\tlearn: 0.2192360\ttotal: 6m 8s\tremaining: 9m 13s\n",
      "40:\tlearn: 0.2175685\ttotal: 6m 20s\tremaining: 9m 7s\n",
      "41:\tlearn: 0.2150778\ttotal: 6m 31s\tremaining: 9m\n",
      "42:\tlearn: 0.2132776\ttotal: 6m 42s\tremaining: 8m 54s\n",
      "43:\tlearn: 0.2105814\ttotal: 6m 54s\tremaining: 8m 47s\n",
      "44:\tlearn: 0.2084795\ttotal: 7m 5s\tremaining: 8m 40s\n",
      "45:\tlearn: 0.2064669\ttotal: 7m 17s\tremaining: 8m 33s\n",
      "46:\tlearn: 0.2046886\ttotal: 7m 28s\tremaining: 8m 25s\n",
      "47:\tlearn: 0.2031029\ttotal: 7m 39s\tremaining: 8m 17s\n",
      "48:\tlearn: 0.2016179\ttotal: 7m 50s\tremaining: 8m 10s\n",
      "49:\tlearn: 0.1995231\ttotal: 8m 1s\tremaining: 8m 1s\n",
      "50:\tlearn: 0.1976964\ttotal: 8m 12s\tremaining: 7m 53s\n",
      "51:\tlearn: 0.1952374\ttotal: 8m 24s\tremaining: 7m 45s\n",
      "52:\tlearn: 0.1938066\ttotal: 8m 35s\tremaining: 7m 36s\n",
      "53:\tlearn: 0.1925282\ttotal: 8m 46s\tremaining: 7m 28s\n",
      "54:\tlearn: 0.1912109\ttotal: 8m 57s\tremaining: 7m 20s\n",
      "55:\tlearn: 0.1887919\ttotal: 9m 9s\tremaining: 7m 11s\n",
      "56:\tlearn: 0.1875804\ttotal: 9m 20s\tremaining: 7m 2s\n",
      "57:\tlearn: 0.1863089\ttotal: 9m 31s\tremaining: 6m 54s\n",
      "58:\tlearn: 0.1837810\ttotal: 9m 43s\tremaining: 6m 45s\n",
      "59:\tlearn: 0.1825471\ttotal: 9m 55s\tremaining: 6m 36s\n",
      "60:\tlearn: 0.1810458\ttotal: 10m 6s\tremaining: 6m 27s\n",
      "61:\tlearn: 0.1794618\ttotal: 10m 17s\tremaining: 6m 18s\n",
      "62:\tlearn: 0.1783557\ttotal: 10m 29s\tremaining: 6m 9s\n",
      "63:\tlearn: 0.1772099\ttotal: 10m 41s\tremaining: 6m\n",
      "64:\tlearn: 0.1757608\ttotal: 10m 52s\tremaining: 5m 51s\n",
      "65:\tlearn: 0.1745435\ttotal: 11m 4s\tremaining: 5m 42s\n",
      "66:\tlearn: 0.1735090\ttotal: 11m 16s\tremaining: 5m 33s\n",
      "67:\tlearn: 0.1724175\ttotal: 11m 28s\tremaining: 5m 23s\n",
      "68:\tlearn: 0.1714414\ttotal: 11m 40s\tremaining: 5m 14s\n",
      "69:\tlearn: 0.1701137\ttotal: 11m 52s\tremaining: 5m 5s\n",
      "70:\tlearn: 0.1690129\ttotal: 12m 4s\tremaining: 4m 56s\n",
      "71:\tlearn: 0.1680035\ttotal: 12m 17s\tremaining: 4m 46s\n",
      "72:\tlearn: 0.1659992\ttotal: 12m 29s\tremaining: 4m 37s\n",
      "73:\tlearn: 0.1646028\ttotal: 12m 41s\tremaining: 4m 27s\n",
      "74:\tlearn: 0.1636686\ttotal: 12m 53s\tremaining: 4m 17s\n",
      "75:\tlearn: 0.1624961\ttotal: 13m 5s\tremaining: 4m 8s\n",
      "76:\tlearn: 0.1608215\ttotal: 13m 17s\tremaining: 3m 58s\n",
      "77:\tlearn: 0.1598933\ttotal: 13m 29s\tremaining: 3m 48s\n",
      "78:\tlearn: 0.1587457\ttotal: 13m 41s\tremaining: 3m 38s\n",
      "79:\tlearn: 0.1578141\ttotal: 13m 53s\tremaining: 3m 28s\n",
      "80:\tlearn: 0.1568824\ttotal: 14m 5s\tremaining: 3m 18s\n",
      "81:\tlearn: 0.1559452\ttotal: 14m 17s\tremaining: 3m 8s\n",
      "82:\tlearn: 0.1550032\ttotal: 14m 29s\tremaining: 2m 58s\n",
      "83:\tlearn: 0.1537483\ttotal: 14m 41s\tremaining: 2m 47s\n",
      "84:\tlearn: 0.1528018\ttotal: 14m 53s\tremaining: 2m 37s\n",
      "85:\tlearn: 0.1518527\ttotal: 15m 5s\tremaining: 2m 27s\n",
      "86:\tlearn: 0.1505896\ttotal: 15m 17s\tremaining: 2m 17s\n",
      "87:\tlearn: 0.1496279\ttotal: 15m 29s\tremaining: 2m 6s\n",
      "88:\tlearn: 0.1486732\ttotal: 15m 41s\tremaining: 1m 56s\n",
      "89:\tlearn: 0.1477260\ttotal: 15m 53s\tremaining: 1m 45s\n",
      "90:\tlearn: 0.1468037\ttotal: 16m 5s\tremaining: 1m 35s\n",
      "91:\tlearn: 0.1458671\ttotal: 16m 17s\tremaining: 1m 24s\n",
      "92:\tlearn: 0.1448826\ttotal: 16m 29s\tremaining: 1m 14s\n",
      "93:\tlearn: 0.1440275\ttotal: 16m 41s\tremaining: 1m 3s\n",
      "94:\tlearn: 0.1431743\ttotal: 16m 53s\tremaining: 53.3s\n",
      "95:\tlearn: 0.1415371\ttotal: 17m 5s\tremaining: 42.7s\n",
      "96:\tlearn: 0.1398763\ttotal: 17m 17s\tremaining: 32.1s\n",
      "97:\tlearn: 0.1383742\ttotal: 17m 29s\tremaining: 21.4s\n",
      "98:\tlearn: 0.1375248\ttotal: 17m 41s\tremaining: 10.7s\n",
      "99:\tlearn: 0.1366350\ttotal: 17m 53s\tremaining: 0us\n",
      "31:\tlearn: 0.2390404\ttotal: 2m 58s\tremaining: 6m 19s\n",
      "32:\tlearn: 0.2361303\ttotal: 3m 4s\tremaining: 6m 14s\n",
      "33:\tlearn: 0.2342445\ttotal: 3m 10s\tremaining: 6m 9s\n",
      "34:\tlearn: 0.2326881\ttotal: 3m 15s\tremaining: 6m 3s\n",
      "35:\tlearn: 0.2306449\ttotal: 3m 21s\tremaining: 5m 58s\n",
      "36:\tlearn: 0.2292843\ttotal: 3m 27s\tremaining: 5m 52s\n",
      "0:\tlearn: 0.5261560\ttotal: 7.54s\tremaining: 12m 26s\n",
      "1:\tlearn: 0.4727091\ttotal: 14.9s\tremaining: 12m 11s\n",
      "2:\tlearn: 0.4381209\ttotal: 22.8s\tremaining: 12m 16s\n",
      "3:\tlearn: 0.4182089\ttotal: 30.5s\tremaining: 12m 11s\n",
      "4:\tlearn: 0.4004614\ttotal: 38.2s\tremaining: 12m 6s\n",
      "5:\tlearn: 0.3856363\ttotal: 46.4s\tremaining: 12m 7s\n",
      "6:\tlearn: 0.3695449\ttotal: 54.5s\tremaining: 12m 4s\n",
      "7:\tlearn: 0.3586624\ttotal: 1m 2s\tremaining: 12m 3s\n",
      "8:\tlearn: 0.3522122\ttotal: 1m 11s\tremaining: 12m\n",
      "9:\tlearn: 0.3454039\ttotal: 1m 19s\tremaining: 11m 58s\n",
      "10:\tlearn: 0.3388468\ttotal: 1m 28s\tremaining: 11m 56s\n",
      "11:\tlearn: 0.3312327\ttotal: 1m 37s\tremaining: 11m 54s\n",
      "12:\tlearn: 0.3227898\ttotal: 1m 46s\tremaining: 11m 51s\n",
      "13:\tlearn: 0.3148013\ttotal: 1m 55s\tremaining: 11m 48s\n",
      "14:\tlearn: 0.3059890\ttotal: 2m 5s\tremaining: 11m 50s\n",
      "15:\tlearn: 0.2990708\ttotal: 2m 15s\tremaining: 11m 49s\n",
      "16:\tlearn: 0.2936934\ttotal: 2m 24s\tremaining: 11m 47s\n",
      "17:\tlearn: 0.2871417\ttotal: 2m 35s\tremaining: 11m 47s\n",
      "18:\tlearn: 0.2818953\ttotal: 2m 44s\tremaining: 11m 41s\n",
      "19:\tlearn: 0.2780577\ttotal: 2m 53s\tremaining: 11m 34s\n",
      "20:\tlearn: 0.2735502\ttotal: 3m 3s\tremaining: 11m 29s\n",
      "21:\tlearn: 0.2704632\ttotal: 3m 12s\tremaining: 11m 22s\n",
      "22:\tlearn: 0.2654777\ttotal: 3m 21s\tremaining: 11m 15s\n",
      "23:\tlearn: 0.2621515\ttotal: 3m 31s\tremaining: 11m 8s\n",
      "24:\tlearn: 0.2580379\ttotal: 3m 40s\tremaining: 11m 2s\n",
      "25:\tlearn: 0.2545524\ttotal: 3m 50s\tremaining: 10m 56s\n",
      "26:\tlearn: 0.2517053\ttotal: 4m 1s\tremaining: 10m 51s\n",
      "27:\tlearn: 0.2491737\ttotal: 4m 11s\tremaining: 10m 46s\n",
      "28:\tlearn: 0.2456050\ttotal: 4m 22s\tremaining: 10m 42s\n",
      "29:\tlearn: 0.2431862\ttotal: 4m 33s\tremaining: 10m 37s\n",
      "30:\tlearn: 0.2409181\ttotal: 4m 44s\tremaining: 10m 33s\n",
      "31:\tlearn: 0.2374342\ttotal: 4m 55s\tremaining: 10m 28s\n",
      "32:\tlearn: 0.2343343\ttotal: 5m 7s\tremaining: 10m 23s\n",
      "33:\tlearn: 0.2316241\ttotal: 5m 18s\tremaining: 10m 18s\n",
      "34:\tlearn: 0.2297325\ttotal: 5m 30s\tremaining: 10m 12s\n",
      "35:\tlearn: 0.2265850\ttotal: 5m 41s\tremaining: 10m 7s\n",
      "36:\tlearn: 0.2234141\ttotal: 5m 53s\tremaining: 10m 1s\n",
      "37:\tlearn: 0.2216149\ttotal: 6m 4s\tremaining: 9m 55s\n",
      "38:\tlearn: 0.2193142\ttotal: 6m 16s\tremaining: 9m 48s\n",
      "39:\tlearn: 0.2177262\ttotal: 6m 28s\tremaining: 9m 42s\n",
      "40:\tlearn: 0.2161599\ttotal: 6m 40s\tremaining: 9m 36s\n",
      "41:\tlearn: 0.2138326\ttotal: 6m 52s\tremaining: 9m 29s\n",
      "42:\tlearn: 0.2111736\ttotal: 7m 3s\tremaining: 9m 21s\n",
      "43:\tlearn: 0.2094032\ttotal: 7m 15s\tremaining: 9m 14s\n",
      "44:\tlearn: 0.2066909\ttotal: 7m 27s\tremaining: 9m 7s\n",
      "45:\tlearn: 0.2049364\ttotal: 7m 39s\tremaining: 8m 59s\n",
      "46:\tlearn: 0.2033323\ttotal: 7m 51s\tremaining: 8m 51s\n",
      "47:\tlearn: 0.2016269\ttotal: 8m 2s\tremaining: 8m 42s\n",
      "48:\tlearn: 0.2001689\ttotal: 8m 14s\tremaining: 8m 34s\n",
      "49:\tlearn: 0.1987029\ttotal: 8m 25s\tremaining: 8m 25s\n",
      "50:\tlearn: 0.1973443\ttotal: 8m 37s\tremaining: 8m 17s\n",
      "51:\tlearn: 0.1960592\ttotal: 8m 49s\tremaining: 8m 8s\n",
      "52:\tlearn: 0.1940182\ttotal: 9m 1s\tremaining: 8m\n",
      "53:\tlearn: 0.1925864\ttotal: 9m 13s\tremaining: 7m 51s\n",
      "54:\tlearn: 0.1903986\ttotal: 9m 24s\tremaining: 7m 42s\n",
      "55:\tlearn: 0.1887566\ttotal: 9m 36s\tremaining: 7m 33s\n",
      "56:\tlearn: 0.1872845\ttotal: 9m 49s\tremaining: 7m 24s\n",
      "57:\tlearn: 0.1860347\ttotal: 10m 1s\tremaining: 7m 15s\n",
      "58:\tlearn: 0.1843005\ttotal: 10m 13s\tremaining: 7m 6s\n",
      "59:\tlearn: 0.1830970\ttotal: 10m 25s\tremaining: 6m 56s\n",
      "60:\tlearn: 0.1819399\ttotal: 10m 37s\tremaining: 6m 47s\n",
      "61:\tlearn: 0.1794591\ttotal: 10m 49s\tremaining: 6m 38s\n",
      "62:\tlearn: 0.1783211\ttotal: 11m 1s\tremaining: 6m 28s\n",
      "63:\tlearn: 0.1769886\ttotal: 11m 14s\tremaining: 6m 19s\n",
      "64:\tlearn: 0.1749497\ttotal: 11m 26s\tremaining: 6m 9s\n",
      "65:\tlearn: 0.1738607\ttotal: 11m 39s\tremaining: 6m\n",
      "66:\tlearn: 0.1727284\ttotal: 11m 51s\tremaining: 5m 50s\n",
      "67:\tlearn: 0.1715578\ttotal: 12m 4s\tremaining: 5m 41s\n",
      "68:\tlearn: 0.1705496\ttotal: 12m 17s\tremaining: 5m 31s\n",
      "69:\tlearn: 0.1696321\ttotal: 12m 30s\tremaining: 5m 21s\n",
      "70:\tlearn: 0.1686051\ttotal: 12m 43s\tremaining: 5m 11s\n",
      "71:\tlearn: 0.1676747\ttotal: 12m 55s\tremaining: 5m 1s\n",
      "72:\tlearn: 0.1652435\ttotal: 13m 8s\tremaining: 4m 51s\n",
      "73:\tlearn: 0.1642246\ttotal: 13m 20s\tremaining: 4m 41s\n",
      "74:\tlearn: 0.1621900\ttotal: 13m 33s\tremaining: 4m 31s\n",
      "75:\tlearn: 0.1612900\ttotal: 13m 45s\tremaining: 4m 20s\n",
      "76:\tlearn: 0.1597811\ttotal: 13m 58s\tremaining: 4m 10s\n",
      "77:\tlearn: 0.1579532\ttotal: 14m 11s\tremaining: 4m\n",
      "78:\tlearn: 0.1570554\ttotal: 14m 23s\tremaining: 3m 49s\n",
      "79:\tlearn: 0.1561500\ttotal: 14m 35s\tremaining: 3m 38s\n",
      "80:\tlearn: 0.1552664\ttotal: 14m 48s\tremaining: 3m 28s\n",
      "81:\tlearn: 0.1542899\ttotal: 15m\tremaining: 3m 17s\n",
      "82:\tlearn: 0.1533789\ttotal: 15m 13s\tremaining: 3m 7s\n",
      "83:\tlearn: 0.1524753\ttotal: 15m 25s\tremaining: 2m 56s\n",
      "84:\tlearn: 0.1515765\ttotal: 15m 38s\tremaining: 2m 45s\n",
      "85:\tlearn: 0.1506664\ttotal: 15m 50s\tremaining: 2m 34s\n",
      "86:\tlearn: 0.1496036\ttotal: 16m 3s\tremaining: 2m 23s\n",
      "87:\tlearn: 0.1486854\ttotal: 16m 15s\tremaining: 2m 13s\n",
      "88:\tlearn: 0.1477647\ttotal: 16m 28s\tremaining: 2m 2s\n",
      "89:\tlearn: 0.1468401\ttotal: 16m 41s\tremaining: 1m 51s\n",
      "90:\tlearn: 0.1459224\ttotal: 16m 53s\tremaining: 1m 40s\n",
      "91:\tlearn: 0.1441206\ttotal: 17m 6s\tremaining: 1m 29s\n",
      "92:\tlearn: 0.1432315\ttotal: 17m 18s\tremaining: 1m 18s\n",
      "93:\tlearn: 0.1423754\ttotal: 17m 31s\tremaining: 1m 7s\n",
      "94:\tlearn: 0.1413699\ttotal: 17m 43s\tremaining: 56s\n",
      "95:\tlearn: 0.1397600\ttotal: 17m 56s\tremaining: 44.8s\n",
      "96:\tlearn: 0.1389174\ttotal: 18m 4s\tremaining: 33.5s\n",
      "97:\tlearn: 0.1380826\ttotal: 18m 12s\tremaining: 22.3s\n",
      "98:\tlearn: 0.1372673\ttotal: 18m 21s\tremaining: 11.1s\n",
      "99:\tlearn: 0.1363796\ttotal: 18m 29s\tremaining: 0us\n",
      "37:\tlearn: 0.2278665\ttotal: 3m 32s\tremaining: 5m 47s\n",
      "38:\tlearn: 0.2245099\ttotal: 3m 38s\tremaining: 5m 41s\n",
      "39:\tlearn: 0.2221710\ttotal: 3m 43s\tremaining: 5m 35s\n",
      "40:\tlearn: 0.2207303\ttotal: 3m 50s\tremaining: 5m 31s\n",
      "41:\tlearn: 0.2190282\ttotal: 3m 56s\tremaining: 5m 26s\n",
      "42:\tlearn: 0.2179075\ttotal: 4m 1s\tremaining: 5m 20s\n",
      "43:\tlearn: 0.2161691\ttotal: 4m 7s\tremaining: 5m 14s\n",
      "44:\tlearn: 0.2150138\ttotal: 4m 13s\tremaining: 5m 9s\n",
      "45:\tlearn: 0.2130960\ttotal: 4m 18s\tremaining: 5m 3s\n",
      "46:\tlearn: 0.2119819\ttotal: 4m 24s\tremaining: 4m 57s\n",
      "47:\tlearn: 0.2105156\ttotal: 4m 29s\tremaining: 4m 52s\n",
      "48:\tlearn: 0.2082259\ttotal: 4m 35s\tremaining: 4m 46s\n",
      "49:\tlearn: 0.2070710\ttotal: 4m 40s\tremaining: 4m 40s\n",
      "50:\tlearn: 0.2053182\ttotal: 4m 46s\tremaining: 4m 35s\n",
      "0:\tlearn: 0.5309980\ttotal: 8.9s\tremaining: 14m 41s\n",
      "1:\tlearn: 0.4908670\ttotal: 17.9s\tremaining: 14m 35s\n",
      "2:\tlearn: 0.4588941\ttotal: 27.3s\tremaining: 14m 44s\n",
      "3:\tlearn: 0.4274577\ttotal: 36.8s\tremaining: 14m 42s\n",
      "4:\tlearn: 0.4037866\ttotal: 46.3s\tremaining: 14m 39s\n",
      "5:\tlearn: 0.3847741\ttotal: 56s\tremaining: 14m 37s\n",
      "6:\tlearn: 0.3740298\ttotal: 1m 6s\tremaining: 14m 38s\n",
      "7:\tlearn: 0.3653496\ttotal: 1m 16s\tremaining: 14m 40s\n",
      "8:\tlearn: 0.3554634\ttotal: 1m 26s\tremaining: 14m 39s\n",
      "9:\tlearn: 0.3473797\ttotal: 1m 37s\tremaining: 14m 38s\n",
      "10:\tlearn: 0.3387336\ttotal: 1m 48s\tremaining: 14m 36s\n",
      "11:\tlearn: 0.3320053\ttotal: 1m 59s\tremaining: 14m 37s\n",
      "12:\tlearn: 0.3244233\ttotal: 2m 11s\tremaining: 14m 43s\n",
      "13:\tlearn: 0.3147508\ttotal: 2m 23s\tremaining: 14m 41s\n",
      "14:\tlearn: 0.3068181\ttotal: 2m 35s\tremaining: 14m 42s\n",
      "15:\tlearn: 0.3008082\ttotal: 2m 46s\tremaining: 14m 36s\n",
      "16:\tlearn: 0.2944166\ttotal: 2m 57s\tremaining: 14m 28s\n",
      "17:\tlearn: 0.2886497\ttotal: 3m 9s\tremaining: 14m 24s\n",
      "18:\tlearn: 0.2830708\ttotal: 3m 20s\tremaining: 14m 16s\n",
      "19:\tlearn: 0.2784682\ttotal: 3m 32s\tremaining: 14m 8s\n",
      "20:\tlearn: 0.2740568\ttotal: 3m 43s\tremaining: 14m 1s\n",
      "21:\tlearn: 0.2702511\ttotal: 3m 56s\tremaining: 13m 57s\n",
      "22:\tlearn: 0.2659126\ttotal: 4m 8s\tremaining: 13m 52s\n",
      "23:\tlearn: 0.2623838\ttotal: 4m 21s\tremaining: 13m 47s\n",
      "24:\tlearn: 0.2579091\ttotal: 4m 34s\tremaining: 13m 43s\n",
      "25:\tlearn: 0.2544769\ttotal: 4m 48s\tremaining: 13m 39s\n",
      "26:\tlearn: 0.2509277\ttotal: 5m 1s\tremaining: 13m 35s\n",
      "27:\tlearn: 0.2483337\ttotal: 5m 15s\tremaining: 13m 31s\n",
      "28:\tlearn: 0.2458473\ttotal: 5m 29s\tremaining: 13m 26s\n",
      "29:\tlearn: 0.2423794\ttotal: 5m 43s\tremaining: 13m 21s\n",
      "30:\tlearn: 0.2380634\ttotal: 5m 57s\tremaining: 13m 15s\n",
      "31:\tlearn: 0.2360941\ttotal: 6m 11s\tremaining: 13m 9s\n",
      "32:\tlearn: 0.2323209\ttotal: 6m 25s\tremaining: 13m 3s\n",
      "33:\tlearn: 0.2290963\ttotal: 6m 40s\tremaining: 12m 56s\n",
      "34:\tlearn: 0.2263142\ttotal: 6m 54s\tremaining: 12m 49s\n",
      "35:\tlearn: 0.2242046\ttotal: 7m 8s\tremaining: 12m 42s\n",
      "36:\tlearn: 0.2207933\ttotal: 7m 23s\tremaining: 12m 34s\n",
      "37:\tlearn: 0.2191215\ttotal: 7m 37s\tremaining: 12m 25s\n",
      "38:\tlearn: 0.2165263\ttotal: 7m 51s\tremaining: 12m 16s\n",
      "39:\tlearn: 0.2141472\ttotal: 8m 4s\tremaining: 12m 7s\n",
      "40:\tlearn: 0.2122680\ttotal: 8m 18s\tremaining: 11m 57s\n",
      "41:\tlearn: 0.2103272\ttotal: 8m 32s\tremaining: 11m 48s\n",
      "42:\tlearn: 0.2081327\ttotal: 8m 47s\tremaining: 11m 39s\n",
      "43:\tlearn: 0.2067509\ttotal: 9m 1s\tremaining: 11m 29s\n",
      "44:\tlearn: 0.2040939\ttotal: 9m 15s\tremaining: 11m 19s\n",
      "45:\tlearn: 0.2024866\ttotal: 9m 29s\tremaining: 11m 8s\n",
      "46:\tlearn: 0.2005274\ttotal: 9m 44s\tremaining: 10m 58s\n",
      "47:\tlearn: 0.1988733\ttotal: 9m 58s\tremaining: 10m 48s\n",
      "48:\tlearn: 0.1966532\ttotal: 10m 13s\tremaining: 10m 38s\n",
      "49:\tlearn: 0.1936655\ttotal: 10m 28s\tremaining: 10m 28s\n",
      "50:\tlearn: 0.1922580\ttotal: 10m 42s\tremaining: 10m 17s\n",
      "51:\tlearn: 0.1907021\ttotal: 10m 57s\tremaining: 10m 6s\n",
      "52:\tlearn: 0.1891471\ttotal: 11m 11s\tremaining: 9m 55s\n",
      "53:\tlearn: 0.1877560\ttotal: 11m 26s\tremaining: 9m 45s\n",
      "54:\tlearn: 0.1863367\ttotal: 11m 41s\tremaining: 9m 34s\n",
      "55:\tlearn: 0.1850812\ttotal: 11m 56s\tremaining: 9m 23s\n",
      "56:\tlearn: 0.1836006\ttotal: 12m 12s\tremaining: 9m 12s\n",
      "57:\tlearn: 0.1823968\ttotal: 12m 27s\tremaining: 9m 1s\n",
      "58:\tlearn: 0.1807488\ttotal: 12m 42s\tremaining: 8m 49s\n",
      "59:\tlearn: 0.1779512\ttotal: 12m 57s\tremaining: 8m 38s\n",
      "60:\tlearn: 0.1766185\ttotal: 13m 12s\tremaining: 8m 26s\n",
      "61:\tlearn: 0.1753905\ttotal: 13m 27s\tremaining: 8m 15s\n",
      "62:\tlearn: 0.1733045\ttotal: 13m 42s\tremaining: 8m 3s\n",
      "63:\tlearn: 0.1721668\ttotal: 13m 57s\tremaining: 7m 51s\n",
      "64:\tlearn: 0.1710793\ttotal: 14m 12s\tremaining: 7m 39s\n",
      "65:\tlearn: 0.1696454\ttotal: 14m 27s\tremaining: 7m 27s\n",
      "66:\tlearn: 0.1685921\ttotal: 14m 42s\tremaining: 7m 14s\n",
      "67:\tlearn: 0.1670890\ttotal: 14m 57s\tremaining: 7m 2s\n",
      "68:\tlearn: 0.1660219\ttotal: 15m 12s\tremaining: 6m 49s\n",
      "69:\tlearn: 0.1649885\ttotal: 15m 27s\tremaining: 6m 37s\n",
      "70:\tlearn: 0.1639668\ttotal: 15m 42s\tremaining: 6m 24s\n",
      "71:\tlearn: 0.1629172\ttotal: 15m 57s\tremaining: 6m 12s\n",
      "72:\tlearn: 0.1619558\ttotal: 16m 12s\tremaining: 5m 59s\n",
      "73:\tlearn: 0.1602322\ttotal: 16m 27s\tremaining: 5m 46s\n",
      "74:\tlearn: 0.1592903\ttotal: 16m 42s\tremaining: 5m 34s\n",
      "75:\tlearn: 0.1577338\ttotal: 16m 56s\tremaining: 5m 21s\n",
      "76:\tlearn: 0.1567852\ttotal: 17m 11s\tremaining: 5m 8s\n",
      "77:\tlearn: 0.1557154\ttotal: 17m 27s\tremaining: 4m 55s\n",
      "78:\tlearn: 0.1547515\ttotal: 17m 42s\tremaining: 4m 42s\n",
      "79:\tlearn: 0.1538090\ttotal: 17m 56s\tremaining: 4m 29s\n",
      "80:\tlearn: 0.1528379\ttotal: 18m 6s\tremaining: 4m 14s\n",
      "81:\tlearn: 0.1518640\ttotal: 18m 16s\tremaining: 4m\n",
      "82:\tlearn: 0.1508913\ttotal: 18m 26s\tremaining: 3m 46s\n",
      "83:\tlearn: 0.1499106\ttotal: 18m 33s\tremaining: 3m 32s\n",
      "84:\tlearn: 0.1489278\ttotal: 18m 38s\tremaining: 3m 17s\n",
      "85:\tlearn: 0.1479765\ttotal: 18m 43s\tremaining: 3m 2s\n",
      "86:\tlearn: 0.1466646\ttotal: 18m 48s\tremaining: 2m 48s\n",
      "87:\tlearn: 0.1457493\ttotal: 18m 53s\tremaining: 2m 34s\n",
      "88:\tlearn: 0.1439698\ttotal: 18m 58s\tremaining: 2m 20s\n",
      "89:\tlearn: 0.1430948\ttotal: 19m 3s\tremaining: 2m 7s\n",
      "90:\tlearn: 0.1421608\ttotal: 19m 8s\tremaining: 1m 53s\n",
      "91:\tlearn: 0.1413165\ttotal: 19m 12s\tremaining: 1m 40s\n",
      "92:\tlearn: 0.1404083\ttotal: 19m 17s\tremaining: 1m 27s\n",
      "93:\tlearn: 0.1396052\ttotal: 19m 22s\tremaining: 1m 14s\n",
      "94:\tlearn: 0.1385851\ttotal: 19m 27s\tremaining: 1m 1s\n",
      "95:\tlearn: 0.1370041\ttotal: 19m 32s\tremaining: 48.9s\n",
      "96:\tlearn: 0.1362176\ttotal: 19m 37s\tremaining: 36.4s\n",
      "97:\tlearn: 0.1354373\ttotal: 19m 42s\tremaining: 24.1s\n",
      "98:\tlearn: 0.1346661\ttotal: 19m 47s\tremaining: 12s\n",
      "99:\tlearn: 0.1328203\ttotal: 19m 51s\tremaining: 0us\n",
      "51:\tlearn: 0.2039429\ttotal: 4m 51s\tremaining: 4m 29s\n",
      "52:\tlearn: 0.2020853\ttotal: 4m 57s\tremaining: 4m 23s\n",
      "53:\tlearn: 0.2010601\ttotal: 5m 3s\tremaining: 4m 18s\n",
      "54:\tlearn: 0.1998920\ttotal: 5m 8s\tremaining: 4m 12s\n",
      "55:\tlearn: 0.1986341\ttotal: 5m 14s\tremaining: 4m 7s\n",
      "56:\tlearn: 0.1974895\ttotal: 5m 20s\tremaining: 4m 1s\n",
      "57:\tlearn: 0.1958633\ttotal: 5m 25s\tremaining: 3m 55s\n",
      "58:\tlearn: 0.1938610\ttotal: 5m 31s\tremaining: 3m 50s\n",
      "59:\tlearn: 0.1927955\ttotal: 5m 36s\tremaining: 3m 44s\n",
      "60:\tlearn: 0.1912791\ttotal: 5m 42s\tremaining: 3m 38s\n",
      "61:\tlearn: 0.1902288\ttotal: 5m 47s\tremaining: 3m 33s\n",
      "62:\tlearn: 0.1890215\ttotal: 5m 53s\tremaining: 3m 27s\n",
      "63:\tlearn: 0.1878463\ttotal: 5m 58s\tremaining: 3m 21s\n",
      "64:\tlearn: 0.1865497\ttotal: 6m 4s\tremaining: 3m 16s\n",
      "65:\tlearn: 0.1850911\ttotal: 6m 10s\tremaining: 3m 10s\n",
      "66:\tlearn: 0.1841046\ttotal: 6m 15s\tremaining: 3m 4s\n",
      "67:\tlearn: 0.1831466\ttotal: 6m 21s\tremaining: 2m 59s\n",
      "68:\tlearn: 0.1822684\ttotal: 6m 26s\tremaining: 2m 53s\n",
      "69:\tlearn: 0.1810250\ttotal: 6m 32s\tremaining: 2m 48s\n",
      "70:\tlearn: 0.1794481\ttotal: 6m 37s\tremaining: 2m 42s\n",
      "71:\tlearn: 0.1786137\ttotal: 6m 43s\tremaining: 2m 36s\n",
      "72:\tlearn: 0.1770182\ttotal: 6m 48s\tremaining: 2m 31s\n",
      "73:\tlearn: 0.1760994\ttotal: 6m 54s\tremaining: 2m 25s\n",
      "74:\tlearn: 0.1752809\ttotal: 6m 59s\tremaining: 2m 19s\n",
      "75:\tlearn: 0.1744441\ttotal: 7m 5s\tremaining: 2m 14s\n",
      "76:\tlearn: 0.1736653\ttotal: 7m 10s\tremaining: 2m 8s\n",
      "77:\tlearn: 0.1729003\ttotal: 7m 16s\tremaining: 2m 3s\n",
      "78:\tlearn: 0.1721605\ttotal: 7m 21s\tremaining: 1m 57s\n",
      "79:\tlearn: 0.1710655\ttotal: 7m 27s\tremaining: 1m 51s\n",
      "80:\tlearn: 0.1703319\ttotal: 7m 33s\tremaining: 1m 46s\n",
      "81:\tlearn: 0.1695691\ttotal: 7m 40s\tremaining: 1m 41s\n",
      "82:\tlearn: 0.1681579\ttotal: 7m 46s\tremaining: 1m 35s\n",
      "83:\tlearn: 0.1670472\ttotal: 7m 53s\tremaining: 1m 30s\n",
      "84:\tlearn: 0.1662643\ttotal: 7m 59s\tremaining: 1m 24s\n",
      "85:\tlearn: 0.1650137\ttotal: 8m 4s\tremaining: 1m 18s\n",
      "86:\tlearn: 0.1639527\ttotal: 8m 10s\tremaining: 1m 13s\n",
      "87:\tlearn: 0.1631845\ttotal: 8m 15s\tremaining: 1m 7s\n",
      "88:\tlearn: 0.1616684\ttotal: 8m 21s\tremaining: 1m 1s\n",
      "89:\tlearn: 0.1609474\ttotal: 8m 27s\tremaining: 56.4s\n",
      "90:\tlearn: 0.1602926\ttotal: 8m 32s\tremaining: 50.7s\n",
      "91:\tlearn: 0.1596371\ttotal: 8m 38s\tremaining: 45.1s\n",
      "92:\tlearn: 0.1586371\ttotal: 8m 44s\tremaining: 39.4s\n",
      "93:\tlearn: 0.1577215\ttotal: 8m 49s\tremaining: 33.8s\n",
      "94:\tlearn: 0.1570513\ttotal: 8m 55s\tremaining: 28.2s\n",
      "95:\tlearn: 0.1557752\ttotal: 9m\tremaining: 22.5s\n",
      "96:\tlearn: 0.1551319\ttotal: 9m 6s\tremaining: 16.9s\n",
      "97:\tlearn: 0.1538730\ttotal: 9m 11s\tremaining: 11.3s\n",
      "98:\tlearn: 0.1532378\ttotal: 9m 17s\tremaining: 5.63s\n",
      "99:\tlearn: 0.1515643\ttotal: 9m 23s\tremaining: 0us\n",
      "CPU times: user 1h 8min 9s, sys: 15.8 s, total: 1h 8min 25s\n",
      "Wall time: 29min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7115858579175692"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CBC = CatBoostClassifier()\n",
    "\n",
    "\n",
    "parameters = {'depth': [10],\n",
    "              'learning_rate' : [1],\n",
    "              'iterations' : [100],\n",
    "              'auto_class_weights': ['Balanced']\n",
    "             }\n",
    "\n",
    "Grid_CBC = GridSearchCV(estimator=CBC, \n",
    "                        param_grid = parameters, \n",
    "                        scoring = 'f1',\n",
    "                        cv = 3, \n",
    "                        n_jobs=-1\n",
    "                        )\n",
    "\n",
    "Grid_CBC.fit(tf_idf_train, target_train)\n",
    "Grid_CBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707798225870515"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_CBC.best_estimator_\n",
    "f1_score(target_test, Grid_CBC.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке получили результаты выше пороговой:\n",
    "- На логистической регрессии __0.754__\n",
    "- На Catboost __0.71__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с нехваткой ресурсов для работы с BERT, оставим только 2000 объектов и будем использовать DistilBERT. Более облегченную версию BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\n\\n i think the original explanation was ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you did not answer my question again. \\n\\nques...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"please do not add nonsense to wikipedia. it i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surely though there must be something to indic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>university college of gävle\\nhi - thanks for t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  \"\\n\\n i think the original explanation was ter...      0\n",
       "1  you did not answer my question again. \\n\\nques...      1\n",
       "2  \"please do not add nonsense to wikipedia. it i...      0\n",
       "3  surely though there must be something to indic...      0\n",
       "4  university college of gävle\\nhi - thanks for t...      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki = df_wiki.drop(columns = {'lemm_text'}, axis = 1)\n",
    "df_wiki = df_wiki.sample(2000).reset_index(drop = True)\n",
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предобученной модели DistilBERT и токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Загрузка предобученной модели/токенизатора \n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем токенизировать набор данных. Токенизируем и обрабатываем все предложения вместе в одном пакете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = df_wiki.text.apply(lambda x: tokenizer.encode(x, add_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [101, 1000, 1045, 2228, 1996, 2434, 7526, 2001...\n",
       "1    [101, 2017, 2106, 2025, 3437, 2026, 3160, 2153...\n",
       "2    [101, 1000, 3531, 2079, 2025, 5587, 14652, 200...\n",
       "3    [101, 7543, 2295, 2045, 2442, 2022, 2242, 2000...\n",
       "4    [101, 2118, 2267, 1997, 11721, 2615, 2571, 763...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    tokenized.apply(lambda x: len(x)), \n",
    "    bins = 'auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим объекты с количеством токенов более 512. BERT не схваает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_index = []\n",
    "for i in range(len(tokenized)):\n",
    "    if (len(tokenized[i]) > 512):\n",
    "        drop_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized.drop(index = drop_index, inplace = True)\n",
    "df_wiki.drop(index = drop_index, inplace = True)\n",
    "\n",
    "plt.hist(\n",
    "    tokenized.apply(lambda x: len(x)), \n",
    "    bins = 'auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1961 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1961 non-null   object\n",
      " 1   toxic   1961 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 46.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_wiki.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_short = tokenized.sample(1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325     [101, 4931, 999, 2053, 2062, 9180, 2100, 1011,...\n",
       "1473    [101, 1000, 7632, 2045, 4283, 2005, 2115, 2785...\n",
       "473     [101, 2625, 2066, 3085, 7696, 2182, 1012, 2928...\n",
       "1482    [101, 1000, 1063, 1064, 2806, 1027, 1000, 1000...\n",
       "1098    [101, 1000, 2026, 21792, 2050, 4283, 4283, 200...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki_short = df_wiki.loc[tokenized_short.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>hey! \\n\\nno more hanky-panky on a shrunken san...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>\"\\n\\nhi there\\n\\nthanks for your kind comment!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>less likeable messages here. mark i know you a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>\"\\n{| style=\"\"background-color:#f5fffa; paddin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>\"\\n\\n my rfa \\n\\nthanks  thanks for your recen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxic\n",
       "325   hey! \\n\\nno more hanky-panky on a shrunken san...      0\n",
       "1473  \"\\n\\nhi there\\n\\nthanks for your kind comment!...      0\n",
       "473   less likeable messages here. mark i know you a...      0\n",
       "1482  \"\\n{| style=\"\"background-color:#f5fffa; paddin...      0\n",
       "1098  \"\\n\\n my rfa \\n\\nthanks  thanks for your recen...      0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После токенизации __tokenized__ представляет собой список (или объект Series/DataFrame из pandas). Мы хотим, чтобы BERT обрабатывал все наши примеры одновременно (как один пакет). Так будет быстрее. По этой причине нам нужно привести все списки до одинакового размера, чтобы мы могли представить вектора как один двумерный массив, а не список списков разной длины.\n",
    "\n",
    "Таким образом, мы получаем матрицу/тензор, который можно передавать BERT'у:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized_short.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized_short.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш набор данных теперь находится в переменной padded с размером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 512)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы напрямую отправим padded в BERT, это немного запутает его. \n",
    "\n",
    "Теперь поясним модели, что нули не несут значимой информации. Это нужно для компоненты модели, которая называется «внимание» (англ. attention). Отбросим эти токены и «создадим маску» для действительно важных токенов, то есть укажем нулевые и не нулевые значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 512)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим входной вектор из матрицы токенов и передадим его в DistilBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60144522197e4f56bfc383ad8691d01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# сделаем пустой список для хранения эмбеддингов\n",
    "embeddings = []\n",
    "\n",
    "# Сделаем цикл по батчам. Отображать прогресс будет функция notebook()\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    # преобразуем данные\n",
    "    batch = torch.LongTensor(padded[batch_size * i: batch_size * (i+1)]) \n",
    "    # преобразуем маску\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size * i:batch_size*(i+1)])\n",
    "    \n",
    "    # Для ускорения вычисления функцией no_grad() (англ. no gradient, «нет градиента») \n",
    "    # в библиотеке torch укажем, что градиенты не нужны: модель BERT обучать не будем.  \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask = attention_mask_batch)\n",
    "        \n",
    "    # Из полученного тензора извлечём нужные элементы и добавим в список всех эмбеддингов\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()\n",
    "features = pd.DataFrame(np.concatenate(embeddings))\n",
    "\n",
    "target = df_wiki_short['toxic']\n",
    "target = target.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим фичи и таргеты\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = 0.2,random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим с кросс-валидацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 s, sys: 6.51 s, total: 48.1 s\n",
      "Wall time: 8.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6067415730337079"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "lr_model = LogisticRegression(random_state = 123, \n",
    "                              solver = 'liblinear', \n",
    "                              class_weight={1: 9})\n",
    "\n",
    "grid_search = GridSearchCV(lr_model, # задаем модель\n",
    "                           lr_parameters, # гиперпараметры\n",
    "                           cv = 5, # количество разбиений на кросс-валидацию ( < 3 делать не стоит)\n",
    "                           scoring = 'f1' # по какой метрике будем оценивать модель \n",
    "                           )  \n",
    "#обучение модели \n",
    "grid_search.fit(features_train, target_train)\n",
    "grid_search.best_estimator_\n",
    "f1_score(target_test, grid_search.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "0:\tlearn: 0.4013888\ttotal: 49.5ms\tremaining: 4.9s\n",
      "1:\tlearn: 0.3319241\ttotal: 81.5ms\tremaining: 3.99s\n",
      "2:\tlearn: 0.2608376\ttotal: 114ms\tremaining: 3.69s\n",
      "3:\tlearn: 0.2063914\ttotal: 149ms\tremaining: 3.56s\n",
      "4:\tlearn: 0.1651358\ttotal: 182ms\tremaining: 3.46s\n",
      "5:\tlearn: 0.1440987\ttotal: 216ms\tremaining: 3.38s\n",
      "6:\tlearn: 0.1186688\ttotal: 253ms\tremaining: 3.35s\n",
      "7:\tlearn: 0.0960855\ttotal: 292ms\tremaining: 3.36s\n",
      "8:\tlearn: 0.0773968\ttotal: 332ms\tremaining: 3.36s\n",
      "9:\tlearn: 0.0730385\ttotal: 363ms\tremaining: 3.26s\n",
      "10:\tlearn: 0.0613917\ttotal: 394ms\tremaining: 3.19s\n",
      "11:\tlearn: 0.0528494\ttotal: 432ms\tremaining: 3.16s\n",
      "12:\tlearn: 0.0428810\ttotal: 474ms\tremaining: 3.17s\n",
      "13:\tlearn: 0.0414051\ttotal: 518ms\tremaining: 3.18s\n",
      "14:\tlearn: 0.0354475\ttotal: 561ms\tremaining: 3.18s\n",
      "15:\tlearn: 0.0294516\ttotal: 604ms\tremaining: 3.17s\n",
      "16:\tlearn: 0.0266822\ttotal: 648ms\tremaining: 3.16s\n",
      "17:\tlearn: 0.0255150\ttotal: 693ms\tremaining: 3.15s\n",
      "18:\tlearn: 0.0232240\ttotal: 732ms\tremaining: 3.12s\n",
      "19:\tlearn: 0.0205454\ttotal: 775ms\tremaining: 3.1s\n",
      "20:\tlearn: 0.0183937\ttotal: 815ms\tremaining: 3.06s\n",
      "21:\tlearn: 0.0155333\ttotal: 856ms\tremaining: 3.04s\n",
      "22:\tlearn: 0.0151384\ttotal: 897ms\tremaining: 3s\n",
      "23:\tlearn: 0.0134125\ttotal: 940ms\tremaining: 2.98s\n",
      "24:\tlearn: 0.0109754\ttotal: 974ms\tremaining: 2.92s\n",
      "25:\tlearn: 0.0099410\ttotal: 1.01s\tremaining: 2.87s\n",
      "26:\tlearn: 0.0088126\ttotal: 1.04s\tremaining: 2.81s\n",
      "27:\tlearn: 0.0079711\ttotal: 1.08s\tremaining: 2.77s\n",
      "28:\tlearn: 0.0072750\ttotal: 1.11s\tremaining: 2.72s\n",
      "29:\tlearn: 0.0069236\ttotal: 1.15s\tremaining: 2.69s\n",
      "30:\tlearn: 0.0067689\ttotal: 1.19s\tremaining: 2.65s\n",
      "31:\tlearn: 0.0059131\ttotal: 1.23s\tremaining: 2.61s\n",
      "32:\tlearn: 0.0055499\ttotal: 1.27s\tremaining: 2.58s\n",
      "33:\tlearn: 0.0052268\ttotal: 1.31s\tremaining: 2.54s\n",
      "34:\tlearn: 0.0047957\ttotal: 1.35s\tremaining: 2.51s\n",
      "35:\tlearn: 0.0047688\ttotal: 1.39s\tremaining: 2.47s\n",
      "36:\tlearn: 0.0047687\ttotal: 1.43s\tremaining: 2.43s\n",
      "37:\tlearn: 0.0046682\ttotal: 1.46s\tremaining: 2.39s\n",
      "38:\tlearn: 0.0045163\ttotal: 1.5s\tremaining: 2.35s\n",
      "39:\tlearn: 0.0042213\ttotal: 1.53s\tremaining: 2.3s\n",
      "40:\tlearn: 0.0042208\ttotal: 1.57s\tremaining: 2.26s\n",
      "41:\tlearn: 0.0039199\ttotal: 1.61s\tremaining: 2.22s\n",
      "42:\tlearn: 0.0039198\ttotal: 1.65s\tremaining: 2.18s\n",
      "43:\tlearn: 0.0035854\ttotal: 1.68s\tremaining: 2.14s\n",
      "44:\tlearn: 0.0034407\ttotal: 1.72s\tremaining: 2.1s\n",
      "45:\tlearn: 0.0032871\ttotal: 1.76s\tremaining: 2.07s\n",
      "46:\tlearn: 0.0031294\ttotal: 1.8s\tremaining: 2.03s\n",
      "47:\tlearn: 0.0031284\ttotal: 1.83s\tremaining: 1.99s\n",
      "48:\tlearn: 0.0031282\ttotal: 1.87s\tremaining: 1.94s\n",
      "49:\tlearn: 0.0031282\ttotal: 1.9s\tremaining: 1.9s\n",
      "50:\tlearn: 0.0031282\ttotal: 1.94s\tremaining: 1.86s\n",
      "51:\tlearn: 0.0031282\ttotal: 1.97s\tremaining: 1.82s\n",
      "52:\tlearn: 0.0031282\ttotal: 2.01s\tremaining: 1.78s\n",
      "53:\tlearn: 0.0031282\ttotal: 2.05s\tremaining: 1.75s\n",
      "54:\tlearn: 0.0031282\ttotal: 2.09s\tremaining: 1.71s\n",
      "55:\tlearn: 0.0031282\ttotal: 2.13s\tremaining: 1.67s\n",
      "56:\tlearn: 0.0031278\ttotal: 2.17s\tremaining: 1.64s\n",
      "57:\tlearn: 0.0031268\ttotal: 2.21s\tremaining: 1.6s\n",
      "58:\tlearn: 0.0031266\ttotal: 2.24s\tremaining: 1.56s\n",
      "59:\tlearn: 0.0031265\ttotal: 2.28s\tremaining: 1.52s\n",
      "60:\tlearn: 0.0031262\ttotal: 2.32s\tremaining: 1.48s\n",
      "61:\tlearn: 0.0031258\ttotal: 2.36s\tremaining: 1.44s\n",
      "62:\tlearn: 0.0031257\ttotal: 2.39s\tremaining: 1.41s\n",
      "63:\tlearn: 0.0031257\ttotal: 2.43s\tremaining: 1.36s\n",
      "64:\tlearn: 0.0031255\ttotal: 2.46s\tremaining: 1.33s\n",
      "65:\tlearn: 0.0031250\ttotal: 2.5s\tremaining: 1.29s\n",
      "66:\tlearn: 0.0031249\ttotal: 2.53s\tremaining: 1.25s\n",
      "67:\tlearn: 0.0031249\ttotal: 2.57s\tremaining: 1.21s\n",
      "68:\tlearn: 0.0031247\ttotal: 2.6s\tremaining: 1.17s\n",
      "69:\tlearn: 0.0031245\ttotal: 2.63s\tremaining: 1.13s\n",
      "70:\tlearn: 0.0031017\ttotal: 2.67s\tremaining: 1.09s\n",
      "71:\tlearn: 0.0029604\ttotal: 2.71s\tremaining: 1.05s\n",
      "72:\tlearn: 0.0027868\ttotal: 2.74s\tremaining: 1.01s\n",
      "73:\tlearn: 0.0026232\ttotal: 2.78s\tremaining: 976ms\n",
      "74:\tlearn: 0.0026232\ttotal: 2.81s\tremaining: 939ms\n",
      "75:\tlearn: 0.0026232\ttotal: 2.85s\tremaining: 901ms\n",
      "76:\tlearn: 0.0026232\ttotal: 2.89s\tremaining: 862ms\n",
      "77:\tlearn: 0.0026006\ttotal: 2.92s\tremaining: 825ms\n",
      "78:\tlearn: 0.0026006\ttotal: 2.96s\tremaining: 787ms\n",
      "79:\tlearn: 0.0026003\ttotal: 3s\tremaining: 749ms\n",
      "80:\tlearn: 0.0026003\ttotal: 3.03s\tremaining: 711ms\n",
      "81:\tlearn: 0.0026001\ttotal: 3.07s\tremaining: 673ms\n",
      "82:\tlearn: 0.0026000\ttotal: 3.1s\tremaining: 636ms\n",
      "83:\tlearn: 0.0026000\ttotal: 3.14s\tremaining: 599ms\n",
      "84:\tlearn: 0.0026000\ttotal: 3.18s\tremaining: 562ms\n",
      "85:\tlearn: 0.0025998\ttotal: 3.21s\tremaining: 523ms\n",
      "86:\tlearn: 0.0025998\ttotal: 3.25s\tremaining: 485ms\n",
      "87:\tlearn: 0.0025999\ttotal: 3.28s\tremaining: 447ms\n",
      "88:\tlearn: 0.0025998\ttotal: 3.31s\tremaining: 409ms\n",
      "89:\tlearn: 0.0025998\ttotal: 3.35s\tremaining: 372ms\n",
      "90:\tlearn: 0.0025995\ttotal: 3.38s\tremaining: 334ms\n",
      "91:\tlearn: 0.0025995\ttotal: 3.41s\tremaining: 297ms\n",
      "92:\tlearn: 0.0025994\ttotal: 3.45s\tremaining: 260ms\n",
      "93:\tlearn: 0.0025994\ttotal: 3.48s\tremaining: 222ms\n",
      "94:\tlearn: 0.0025858\ttotal: 3.52s\tremaining: 186ms\n",
      "95:\tlearn: 0.0025857\ttotal: 3.56s\tremaining: 148ms\n",
      "96:\tlearn: 0.0025857\ttotal: 3.6s\tremaining: 111ms\n",
      "97:\tlearn: 0.0025857\ttotal: 3.63s\tremaining: 74.2ms\n",
      "98:\tlearn: 0.0025855\ttotal: 3.67s\tremaining: 37.1ms\n",
      "99:\tlearn: 0.0025855\ttotal: 3.71s\tremaining: 0us\n",
      "CPU times: user 23.7 s, sys: 868 ms, total: 24.6 s\n",
      "Wall time: 18.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fc2f6e87730>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#from sklearn.utils.class_weight import compute_class_weight \n",
    "#classes = np.unique(target_train)\n",
    "#weights = compute_class_weight(class_weight='balanced', classes=classes, y=target_train)\n",
    "#class_weights = dict(zip(classes, weights))\n",
    "\n",
    "#CBC = CatBoostClassifier(class_weights=class_weights)\n",
    "\n",
    "CBC = CatBoostClassifier()\n",
    "\n",
    "\n",
    "parameters = {'depth': [5],\n",
    "              'learning_rate' : [1],\n",
    "              'iterations'    : [100],\n",
    "              'auto_class_weights': ['Balanced']\n",
    "             }\n",
    "\n",
    "Grid_CBC = GridSearchCV(estimator=CBC, \n",
    "                        param_grid = parameters, \n",
    "                        scoring = 'f1',\n",
    "                        cv = 3, \n",
    "                        verbose = 50,\n",
    "                        n_jobs=-1\n",
    "                        )\n",
    "\n",
    "Grid_CBC.fit(features_train, target_train)\n",
    "Grid_CBC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_CBC.best_score_\n",
    "f1_score(target_test, Grid_CBC.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак мы обучили несколько моделей для целей определения токсичных описаний для Викишопа.\n",
    "\n",
    "Модель логистической регресии на основе векторизации TF-IDF дала результат по метрике f1 выше порога - 0.754\n",
    "\n",
    "Модели на ембеддингах, к сожалению дали результаты ниже порога. Это связано с небольшим количеством объектов участвующих в обучении из-за высокой потребности в ресурсах к модели BERT.\n",
    "\n",
    "Бустинги очень легко переобучаются. В нашем случае мы классифицируем по сути своей не особо осмысленные вектора, которые ещё и обладают большой размерностью - это, скорее всего, приводит к переобучению и худшим метрикам на тестовой выборке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
